#!/bin/bash

# INTRODUCTION
# This script reads the clipboard when a link or DOI for a scientific paper is copied.
# It then scrapes the HTML page from Sci-Hub.se and tries to download the pdf, and opens
# it in your default PDF viewer.
#--------------------------------------------------------------------#
# DEPENDENCIES:
# 1. curl
# 2. libnotify (for displaying notifications)
# 3. xclip (clipboard manager)
#--------------------------------------------------------------------#
# HOW TO RUN
# 1. Look up any scientific article on google scholar.
# 2. Copy the doi (typically starts with an https://doi.org/... OR you can copy the link of the paper
# 3. Open up the terminal and run the script (make sure script is executable)

dmenuprompt() {

answer=$(echo -e "Yes\nNo" | dmenu -i -p "Keep paper?")

[[ -z $answer ]] && notify-send "$downloaded_paper in $papersdir" && exit;

case $answer in

	"Yes") mv $downloaded_paper "$papersdir" && notify-send "$downloaded_paper saved in $papersdir" ;;
	"No") rm -rf $downloaded_paper && notify-send "$downloaded_paper removed" ;;
	*) exit ;;
esac
}

dependency_check ()
{
	[[ -z $(which notify-send) ]] && \
	echo -e "Missing package: libnotify"
	[[ -z $(which xclip) ]] && \
	echo -e "Missing package: xclip"
	[[ -z $(which curl) ]] && \
	echo -e "Missing package: curl"
}

dependency_check;

papersdir="$HOME/Work/Papers/PIV"

[[ -d $papersdir ]] || papersdir="$HOME/Downloads"

useragent="user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36"
doi=$(xclip -selection clipboard -o)
linkk=$(echo "https://sci-hub.se/"$doi | sed "s/ //g")
tmppaper=$(curl -H "$useragent" -s $linkk | grep "<button onclick" | awk 'BEGIN {FS="\""} {print $2}' | sed "s/location.href='//g;s/'//g;s/?download=true//g")

[[ -z $tmppaper ]] && notify-send "Paper not found" && exit;

two_dashes=$(echo $tmppaper | grep -o "^\/\/");

[[ -z $two_dashes ]] && paper=$tmppaper || paper=$(echo $tmppaper | sed "s/^\/\///")

paper_with_scihub=$(echo "https://$paper")

[[ $paper_with_scihub == "https://sci-hub.se" ]] && notify-send "Paper not found" && exit;

cd $papersdir
curl -H "$useragent" -LsO "$paper_with_scihub" \
	&& downloaded_paper=$(ls -tr *.pdf | tail -n 1)

typee=$(file -b $downloaded_paper 2>/dev/null | cut -d' ' -f1)

if [[ typee == "HTML" || -z $downloaded_paper ]];
then
	paper_with_scihub=$(echo "https://sci-hub.se$paper")
	curl -H "$useragent" -LsO "$paper_with_scihub" \
		&& downloaded_paper=$(ls -tr *.pdf | tail -n 1)
fi

xdg-open $downloaded_paper 2>/dev/null && [[ -z "$(which dmenu)" ]] && exit || dmenuprompt
